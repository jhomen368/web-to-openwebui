# =============================================================================
# Maxroll Guide Site Configuration Template
# =============================================================================
# This template is designed for Maxroll.gg gaming guides.
# Copy this file to data/config/sites/yoursite.yaml and customize.
#
# Tested with: Maxroll Path of Exile 2 Guides
# Compatible with: Maxroll.gg guides (any game)
#
# QUICK START:
#   1. Copy: cp maxroll.yml.example myguide.yaml
#   2. Edit: Change base_url, start_urls, and site name
#   3. Test: webowui validate --site myguide
#   4. Scrape: webowui scrape --site myguide
# =============================================================================

# -----------------------------------------------------------------------------
# Site Identification
# -----------------------------------------------------------------------------
site:
  # Internal identifier (lowercase, no spaces, used for directory names)
  name: "myguide"

  # Human-readable name (used in logs and OpenWebUI knowledge base)
  display_name: "My Maxroll Guide"

  # Base URL of the site
  base_url: "https://maxroll.gg"

  # Starting pages for the scraper
  start_urls:
    - "https://maxroll.gg/poe2/category/guides"
    # Add more start URLs if needed:
    # - "https://maxroll.gg/poe2/build-guides"

# -----------------------------------------------------------------------------
# Crawling Strategy
# -----------------------------------------------------------------------------
crawling:
  # Strategy: "bfs" (breadth-first, recommended), "dfs" (depth-first),
  #           or "best_first" (keyword-based)
  # For guides, "bfs" or "selective" works best
  strategy: "bfs"

  # Maximum depth from start URLs (1 = only pages linked from start page)
  # Increase for comprehensive scraping, decrease for testing
  max_depth: 2

  # Optional: Limit total pages scraped
  max_pages: null

  # Optional: Stream results as they are crawled (vs batch at end)
  streaming: false

  # URL Filters
  filters:
    # URL patterns to follow (Python regex)
    follow_patterns:
      - "^https://maxroll\\.gg/poe2/.*"

    # URL patterns to exclude (Python regex)
    exclude_patterns:
      - ".*#.*"               # Fragment identifiers
      - ".*\\?.*"             # Query parameters (often used for tracking/sorting)
      - ".*/category/.*"      # Category pages (often just lists of links)
      - ".*/tag/.*"           # Tag pages
      - ".*/author/.*"        # Author profiles
      - ".*/search/.*"        # Search results
      - ".*/login.*"          # Login pages
      - ".*/register.*"       # Registration pages

    # Block specific domains (if crawling external links)
    exclude_domains: []

  # Rate limiting (be respectful to the server)
  rate_limit:
    requests_per_second: 1      # 1 request per second (conservative)
    delay_between_requests: 1.0  # Additional 1 second delay
    max_retries: 3               # Retry failed requests 3 times

# -----------------------------------------------------------------------------
# CONTENT PROCESSING PIPELINE
# -----------------------------------------------------------------------------
# The content processing pipeline consists of 3 main stages:
#
# Stage 1: HTML Filtering (html_filtering)
#   - Applied to raw HTML before conversion
#   - Removes tags, links, and low-density blocks
#
# Stage 2: Markdown Processing
#   - 2a: Conversion (markdown_conversion) - HTML to Markdown
#   - 2b: Cleaning (markdown_cleaning) - Profile-based cleanup
#
# Stage 3: Result Filtering (result_filtering)
#   - Final checks on the generated markdown

# -----------------------------------------------------------------------------
# STAGE 1: HTML Filtering
# -----------------------------------------------------------------------------
html_filtering:
  # Heuristic Pruning Filter (aggressive content removal)
  # RECOMMENDED: enabled: false (rely on explicit tags and Stage 2 profiles instead)
  pruning:
    enabled: false
    # threshold: 0.6           # Content density (0.0-1.0)
    # min_word_threshold: 50   # Skip blocks with < N words

  # Basic HTML Filters (Always active if defined)
  # ---------------------------------------------

  # HTML tags to remove (standard HTML tag names ONLY, no classes/IDs)
  # Optimal Safe Set for Maxroll:
  excluded_tags:
    - nav
    - footer
    - aside
    - header

  # Link filtering
  exclude_external_links: true      # Remove links to external sites
  exclude_social_media_links: true  # Remove social media share buttons

  # Block filtering (crawl4ai word_count_threshold)
  # Remove HTML blocks with fewer than N words
  # Set to 10 to prevent aggressive filtering of short but valid content
  min_block_words: 10

# -----------------------------------------------------------------------------
# STAGE 2a: Markdown Conversion
# -----------------------------------------------------------------------------
# Controls how crawl4ai converts HTML to markdown
markdown_conversion:
  # Main content selector (body gets everything, or use specific selector)
  content_selector: "body"

  # Elements to remove before extraction (CSS selectors supported here)
  remove_selectors:
    - "script"     # JavaScript code
    - "style"      # CSS styles
    - "nav"        # Navigation menus
    - "footer"     # Page footers
    - ".ad-container" # Advertisements
    - ".social-share" # Social share buttons
    - ".comments-section" # Comments
    - ".related-posts" # Related posts
    - ".sidebar"   # Sidebars

  # Markdown generation options
  markdown_options:
    include_images: true       # Keep image references
    include_links: true        # Keep hyperlinks
    preserve_structure: true   # Maintain heading hierarchy
    heading_style: "atx"       # Use # for headings (ATX style)

# -----------------------------------------------------------------------------
# STAGE 2b: Markdown Cleaning (Profiles)
# -----------------------------------------------------------------------------
# Applied AFTER markdown generation to handle site-specific patterns
# The Maxroll cleaning profile removes gaming guide boilerplate.
markdown_cleaning:
  # Profile: "maxroll" (recommended for Maxroll sites)
  # This selects the MaxrollProfile class
  profile: "maxroll"

  # Profile-specific options (see cleaning_profiles README for details)
  # These defaults are optimized for Maxroll guides
  config:
    # Maxroll-Specific Cleaning
    remove_navigation: true         # Remove breadcrumbs and menus
    remove_socials: true            # Remove social media links
    remove_comments: true           # Remove comments section
    remove_ads: true                # Remove ad placeholders
    remove_metadata: true           # Remove author/date metadata

    # Optional Filtering
    filter_dead_links: false        # Remove links to non-existent pages

# -----------------------------------------------------------------------------
# STAGE 3: Result Filtering
# -----------------------------------------------------------------------------

# Final checks on the generated content
result_filtering:
  # Minimum page length (characters) - filter out stubs/redirects
  min_page_length: 100

  # Maximum page length (characters) - prevent memory issues
  max_page_length: 500000

  # Only scrape HTML pages
  allowed_content_types:
    - "text/html"

# -----------------------------------------------------------------------------
# OpenWebUI Integration
# -----------------------------------------------------------------------------
openwebui:
  # Knowledge base name in OpenWebUI
  knowledge_name: "My Maxroll Guide"

  # Description shown in OpenWebUI
  description: "Comprehensive Maxroll gaming guide for RAG"

  # Optional: Specify existing knowledge base ID to update (leave blank for new)
  # knowledge_id: "existing-kb-id-here"

  # Automatically upload after scraping
  auto_upload: false

  # Number of files to upload concurrently
  batch_size: 10

  # File deletion behavior when files are removed from scrape:
  # false = Delete file from storage (default, recommended)
  # true = Remove from knowledge but keep file in storage
  preserve_deleted_files: false

  # Auto-rebuild upload_status.json if missing (disaster recovery)
  auto_rebuild_state: true

  # Minimum confidence for state reconstruction: "high", "medium", or "low"
  rebuild_confidence_threshold: "medium"

# -----------------------------------------------------------------------------
# Backup Retention
# -----------------------------------------------------------------------------
retention:
  # Enable automatic backup cleanup
  enabled: true

  # Number of timestamped backup directories to keep (not counting current/)
  keep_backups: 2

  # Run cleanup automatically after each scrape
  auto_cleanup: true

# -----------------------------------------------------------------------------
# Scheduling (for Docker daemon mode)
# -----------------------------------------------------------------------------
schedule:
  # Enable scheduled scraping (useful for Docker deployment)
  enabled: true

  # Schedule type: "cron" (cron syntax) or "interval" (fixed intervals)
  type: "cron"

  # Cron expression (for type: cron)
  # Examples:
  #   "0 2 * * *"      = 2 AM daily
  #   "0 */6 * * *"    = Every 6 hours
  #   "0 0 * * 0"      = Weekly on Sunday midnight
  cron: "0 2 * * *"

  # Timezone for scheduled runs
  timezone: "America/Los_Angeles"

  # Maximum time allowed for scrape before timeout
  timeout_minutes: 60

  # Retry settings for failed scrapes
  retry:
    enabled: true           # Retry on failure
    max_attempts: 3         # Try up to 3 times total
    delay_minutes: 15       # Wait 15 minutes between attempts

# =============================================================================
# TIPS AND BEST PRACTICES
# =============================================================================
#
# 1. MAXROLL SPECIFICS: Maxroll guides are structured with clear sections.
#    The maxroll profile is designed to preserve this structure while removing
#    navigation and ads.
#
# 2. CRAWLING STRATEGY: Use "bfs" or "selective" to crawl guides.
#    "selective" is useful if you only want specific guides (e.g., build guides).
#
# 3. EXCLUDE PATTERNS: Maxroll has many category and tag pages that are just
#    lists of links. Exclude these to focus on the actual guide content.
#
# 4. CLEANING PROFILE: The maxroll profile is site-specific.
#    It handles Maxroll's unique HTML structure and CSS classes.
#
# 5. TESTING: Always validate before first scrape:
#    webowui validate --site myguide
#
# =============================================================================
